{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image warping\n",
    "\n",
    "* Learn to apply different geometric transformations to images, like translation, rotation, affine transformation etc.\n",
    "\n",
    "OpenCV provides two transformation functions, `cv.warpAffine` and `cv.warpPerspective`, with which you can perform all kinds of transformations. `cv.warpAffine` takes a 2x3 transformation matrix while `cv.warpPerspective` takes a 3x3 transformation matrix as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## OpenCV\n",
    "\n",
    "(pytorch)$ conda install -c conda-forge py-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Scaling is just resizing of the image.\n",
    "OpenCV comes with a function `cv.resize()` for this purpose.\n",
    "The size of the image can be specified manually, or you can specify the scaling factor.\n",
    "Different interpolation methods are used.\n",
    "Preferable interpolation methods are `cv.INTER_AREA` for shrinking and `cv.INTER_CUBIC` (slow) & `cv.INTER_LINEAR` for zooming.\n",
    "By default, the interpolation method `cv.INTER_LINEAR` is used for all resizing purposes.\n",
    "\n",
    "* Resizes an image.\n",
    "    * `dst = cv.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]])`\n",
    "        * dsize: output image size\n",
    "        * fx: scale factor along the horizontal axis\n",
    "        * fy: scale factor along the vertical axis;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg')\n",
    "\n",
    "height, width = img.shape[:2]\n",
    "# scale image (1.5x width, 2x height)\n",
    "# TODO\n",
    "dst = ...\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "Translation is the shifting of an object's location.\n",
    "If you know the shift in the (x,y) direction and let it be (tx,ty), you can create the transformation matrix M as follows:\n",
    "\n",
    "$M = \\begin{bmatrix}1 & 0 & t_x\\\\ 0 & 1 & t_y\\end{bmatrix}$\n",
    "\n",
    "You can take make it into a Numpy array of type np.float32 and pass it into the cv.warpAffine() function.\n",
    "\n",
    "* Applies an affine transformation to an image.\n",
    "    * `dst = cv.warpAffine( src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])`\n",
    "    * warning: The third argument of the cv.warpAffine() function is the size of the output image, which should be in the form of **(width, height)**. Remember width = number of columns, and height = number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg',0)\n",
    "\n",
    "# translate image (translation of (100,50))\n",
    "# TODO\n",
    "rows,cols = img.shape\n",
    "M = ...\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation\n",
    "\n",
    "Rotation of an image for an angle Î¸ is achieved by the transformation matrix of the form\n",
    "\n",
    "$M = \\begin{bmatrix} cos\\theta & -sin\\theta \\\\ sin\\theta & cos\\theta \\end{bmatrix}$\n",
    "\n",
    "But OpenCV provides scaled rotation with adjustable center of rotation so that you can rotate at any location you prefer. The modified transformation matrix is given by\n",
    "\n",
    "$M = \\begin{bmatrix} \\alpha & \\beta & (1- \\alpha ) \\cdot center.x - \\beta \\cdot center.y \\\\ - \\beta & \\alpha & \\beta \\cdot center.x + (1- \\alpha ) \\cdot center.y\\end{bmatrix}$\n",
    "\n",
    "where:\n",
    "\n",
    "$ \\alpha = scale \\cdot \\cos \\theta , \\\\ \\beta = scale \\cdot \\sin \\theta$\n",
    "\n",
    "To find this transformation matrix, OpenCV provides a function, `cv.getRotationMatrix2D`. Check out the below example which rotates the image by 90 degree with respect to center without any scaling.\n",
    "\n",
    "* Calculates an affine matrix of 2D rotation.\n",
    "    * `retval = cv.getRotationMatrix2D(center, angle, scale)`\n",
    "\n",
    "* Applies an affine transformation to an image.\n",
    "    * `dst = cv.warpAffine( src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])`\n",
    "    * warning: The third argument of the cv.warpAffine() function is the size of the output image, which should be in the form of **(width, height)**. Remember width = number of columns, and height = number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg',0)\n",
    "\n",
    "# compute rotation matrix and rotate image (center should be image center, angle=45, scale=1)\n",
    "# TODO\n",
    "rows,cols = img.shape # cols-1 and rows-1 are the coordinate limits.\n",
    "M = ...\n",
    "dst = ...\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transformation\n",
    "\n",
    "In affine transformation, all parallel lines in the original image will still be parallel in the output image. To find the transformation matrix, we need three points from the input image and their corresponding locations in the output image. Then cv.getAffineTransform will create a 2x3 matrix which is to be passed to cv.warpAffine.\n",
    "\n",
    "Check the below example, and also look at the green points\n",
    "\n",
    "* Calculates an affine transform from three pairs of the corresponding points.\n",
    "    * `retval = cv.getAffineTransform(src, dst)`\n",
    "\n",
    "* Applies an affine transformation to an image.\n",
    "    * `dst = cv.warpAffine( src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])`\n",
    "    * warning: The third argument of the cv.warpAffine() function is the size of the output image, which should be in the form of **(width, height)**. Remember width = number of columns, and height = number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread('drawing.png')\n",
    "\n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "\n",
    "# draw points\n",
    "for p in pts1:\n",
    "    p = p.astype('int32')\n",
    "    img = cv.circle(img, tuple(p), radius=0, color=(0, 255, 0), thickness=8)\n",
    "\n",
    "# compute affine transformation matrix and transform image\n",
    "# TODO\n",
    "rows,cols,ch = img.shape\n",
    "M = ...\n",
    "dst = ...\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transformation\n",
    "\n",
    "For perspective transformation, you need a 3x3 transformation matrix.\n",
    "Straight lines will remain straight even after the transformation.\n",
    "To find this transformation matrix, you need 4 points on the input image and corresponding points on the output image.\n",
    "Among these 4 points, 3 of them should not be collinear.\n",
    "Then the transformation matrix can be found by the function cv.getPerspectiveTransform.\n",
    "Then apply cv.warpPerspective with this 3x3 transformation matrix.\n",
    "\n",
    "* Calculates a perspective transform from four pairs of the corresponding points.\n",
    "    * `retval = cv.getPerspectiveTransform(src, dst[, solveMethod])`\n",
    "\n",
    "* Applies a perspective transformation to an image:\n",
    "    * `dst = cv.warpPerspective(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv.imread('sudoku.png')\n",
    "\n",
    "\n",
    "pts1 = np.float32([[72,87],[490,70],[40,513],[519,519]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "# draw points\n",
    "for p in pts1:\n",
    "    p = p.astype('int32')\n",
    "    img = cv.circle(img, tuple(p), radius=0, color=(0, 255, 0), thickness=8)\n",
    "\n",
    "rows,cols,ch = img.shape\n",
    "# compute perspective transformation matrix and transform image (dsize=(300,300))\n",
    "# TODO\n",
    "M = ...\n",
    "dst = cv.warpPerspective(img,M,(300,300))\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Use cv.warpPerspective() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg',0)\n",
    "\n",
    "# scale image (0.7x width, 0.5x height)\n",
    "# TODO\n",
    "print(img.shape)\n",
    "rows,cols = img.shape\n",
    "M_scale = ...\n",
    "dst = cv.warpPerspective(img,M_scale,(cols,rows))\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shear\n",
    "\n",
    "Use cv.warpPerspective() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg',0)\n",
    "\n",
    "# shear image x:0.3\n",
    "# TODO\n",
    "print(img.shape)\n",
    "rows,cols = img.shape\n",
    "M_shear = ...\n",
    "dst = ...\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "Use cv.warpPerspective() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg',0)\n",
    "\n",
    "# translate image (translation of (100,50))\n",
    "# TODO\n",
    "rows,cols = img.shape\n",
    "M_translate = ...\n",
    "dst = ...\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation\n",
    "\n",
    "- Use cv.warpPerspective() function.\n",
    "- Don't use cv.getRotationMatrix2D() function\n",
    "- `np.radians(degree)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg',0)\n",
    "\n",
    "# compute rotation matrix and rotate image (center should be image center, angle=45, scale=1)\n",
    "# TODO\n",
    "rows,cols = img.shape # cols-1 and rows-1 are the coordinate limits.\n",
    "degree = 15\n",
    "M_rotate = ...\n",
    "dst = ...\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition\n",
    "\n",
    "- Use cv.warpPerspective() function.\n",
    "- Apply M_scale, M_shear, M_translate, M_rotate in that order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg',0)\n",
    "\n",
    "# compute rotation matrix and rotate image (center should be image center, angle=45, scale=1)\n",
    "# TODO\n",
    "rows,cols = img.shape # cols-1 and rows-1 are the coordinate limits.\n",
    "M = ...\n",
    "dst = ...\n",
    "\n",
    "plt.subplot(121),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(cv.cvtColor(dst,cv.COLOR_BGR2RGB)),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Matrix\n",
    "\n",
    "- Implement getAffineTransform() function\n",
    "- Hints\n",
    "    - Inverse Matrix : np.linalg.inv(mat) \n",
    "    - Matrix Multiplication : np.matmul(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = cv.imread('drawing.png')\n",
    "\n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "\n",
    "# draw points\n",
    "for p in pts1:\n",
    "    p = p.astype('int32')\n",
    "    img = cv.circle(img, tuple(p), radius=0, color=(0, 255, 0), thickness=8)\n",
    "\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "def getAffineTransform(src_pts, target_pts):\n",
    "    # TODO\n",
    "    ...\n",
    "\n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    "dst1 = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "M = getAffineTransform(pts1,pts2)\n",
    "dst2 = cv.warpPerspective(img,M,(cols,rows))\n",
    "\n",
    "plt.subplot(131),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(132),plt.imshow(cv.cvtColor(dst1,cv.COLOR_BGR2RGB)),plt.title('OpenCV results')\n",
    "plt.subplot(133),plt.imshow(cv.cvtColor(dst2,cv.COLOR_BGR2RGB)),plt.title('our results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projective Matrix\n",
    "\n",
    "- Implement getPerspectiveTransform() function\n",
    "- Hints\n",
    "    - Inverse Matrix : np.linalg.inv(mat) \n",
    "    - Matrix Multiplication : np.matmul(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv.imread('sudoku.png')\n",
    "\n",
    "\n",
    "pts1 = np.float32([[72,87],[490,70],[40,513],[519,519]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "\n",
    "# draw points\n",
    "for p in pts1:\n",
    "    p = p.astype('int32')\n",
    "    img = cv.circle(img, tuple(p), radius=0, color=(0, 255, 0), thickness=8)\n",
    "\n",
    "## Affine Matrix\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "\n",
    "# compute perspective transformation matrix and transform image (dsize=(300,300))\n",
    "# TODO\n",
    "def getPerspectiveTransform(src_pts, target_pts):\n",
    "    # TODO\n",
    "    ...\n",
    "\n",
    "M = cv.getPerspectiveTransform(pts1,pts2)\n",
    "dst1 = cv.warpPerspective(img,M,(300,300))\n",
    "\n",
    "M = getPerspectiveTransform(pts1,pts2)\n",
    "dst2 = cv.warpPerspective(img,M,(300,300))\n",
    "\n",
    "plt.subplot(131),plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB)),plt.title('Input')\n",
    "plt.subplot(132),plt.imshow(cv.cvtColor(dst1,cv.COLOR_BGR2RGB)),plt.title('OpenCV results')\n",
    "plt.subplot(133),plt.imshow(cv.cvtColor(dst2,cv.COLOR_BGR2RGB)),plt.title('our results')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
